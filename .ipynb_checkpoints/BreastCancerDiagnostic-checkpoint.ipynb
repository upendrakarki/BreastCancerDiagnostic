{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd                 \n",
    "import matplotlib.pyplot as plt      \n",
    "import numpy as np\n",
    "import theano \n",
    "import keras \n",
    "import tensorflow\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "#visualization\n",
    "import seaborn as sns \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dropout, Flatten, Activation, Dense\n",
    "from keras.layers.convolutional import Convolution2D, Convolution1D,MaxPooling1D\n",
    "#Import models from scikit learn module:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold   #For cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\",header=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 33)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(n=30000 , replace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('id',axis=1,inplace=True)\n",
    "df.drop('Unnamed: 32',axis=1,inplace=True)\n",
    "len(df) #size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>10.750</td>\n",
       "      <td>14.97</td>\n",
       "      <td>68.26</td>\n",
       "      <td>355.3</td>\n",
       "      <td>0.07793</td>\n",
       "      <td>0.05139</td>\n",
       "      <td>0.02251</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950</td>\n",
       "      <td>20.72</td>\n",
       "      <td>77.79</td>\n",
       "      <td>441.2</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.09755</td>\n",
       "      <td>0.03413</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.06769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>17.570</td>\n",
       "      <td>15.05</td>\n",
       "      <td>115.00</td>\n",
       "      <td>955.1</td>\n",
       "      <td>0.09847</td>\n",
       "      <td>0.11570</td>\n",
       "      <td>0.09875</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>...</td>\n",
       "      <td>20.010</td>\n",
       "      <td>19.52</td>\n",
       "      <td>134.90</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>0.24890</td>\n",
       "      <td>0.14560</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.07919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>15.120</td>\n",
       "      <td>16.68</td>\n",
       "      <td>98.78</td>\n",
       "      <td>716.6</td>\n",
       "      <td>0.08876</td>\n",
       "      <td>0.09588</td>\n",
       "      <td>0.07550</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>...</td>\n",
       "      <td>17.770</td>\n",
       "      <td>20.24</td>\n",
       "      <td>117.70</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.33270</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.09740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>8.964</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>9.667</td>\n",
       "      <td>18.49</td>\n",
       "      <td>61.49</td>\n",
       "      <td>289.1</td>\n",
       "      <td>0.08946</td>\n",
       "      <td>0.06258</td>\n",
       "      <td>0.02948</td>\n",
       "      <td>0.015140</td>\n",
       "      <td>0.2238</td>\n",
       "      <td>...</td>\n",
       "      <td>11.140</td>\n",
       "      <td>25.62</td>\n",
       "      <td>70.88</td>\n",
       "      <td>385.2</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.1542</td>\n",
       "      <td>0.12770</td>\n",
       "      <td>0.06560</td>\n",
       "      <td>0.3174</td>\n",
       "      <td>0.08524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "144          0       10.750         14.97           68.26      355.3   \n",
       "29           1       17.570         15.05          115.00      955.1   \n",
       "205          1       15.120         16.68           98.78      716.6   \n",
       "46           0        8.196         16.84           51.71      201.9   \n",
       "470          0        9.667         18.49           61.49      289.1   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "144          0.07793           0.05139         0.02251             0.007875   \n",
       "29           0.09847           0.11570         0.09875             0.079530   \n",
       "205          0.08876           0.09588         0.07550             0.040790   \n",
       "46           0.08600           0.05943         0.01588             0.005917   \n",
       "470          0.08946           0.06258         0.02948             0.015140   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "144         0.1399  ...        11.950          20.72            77.79   \n",
       "29          0.1739  ...        20.010          19.52           134.90   \n",
       "205         0.1594  ...        17.770          20.24           117.70   \n",
       "46          0.1769  ...         8.964          21.96            57.26   \n",
       "470         0.2238  ...        11.140          25.62            70.88   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "144       441.2            0.1076             0.1223          0.09755   \n",
       "29       1227.0            0.1255             0.2812          0.24890   \n",
       "205       989.5            0.1491             0.3331          0.33270   \n",
       "46        242.2            0.1297             0.1357          0.06880   \n",
       "470       385.2            0.1234             0.1542          0.12770   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "144               0.03413          0.2300                  0.06769  \n",
       "29                0.14560          0.2756                  0.07919  \n",
       "205               0.12520          0.3415                  0.09740  \n",
       "46                0.02564          0.3105                  0.07409  \n",
       "470               0.06560          0.3174                  0.08524  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis.unique()\n",
    "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "Number of Malignant cases:  11296 (37.65%)\n",
      "Number of Benign cases: 18704 (62.35%)\n"
     ]
    }
   ],
   "source": [
    "num_obs = len(df)\n",
    "print (num_obs)\n",
    "num_true = len(df.loc[df['diagnosis'] == 1])\n",
    "num_false = len(df.loc[df['diagnosis'] == 0])\n",
    "print(\"Number of Malignant cases:  {0} ({1:2.2f}%)\".format(num_true, (float (num_true)/num_obs) * 100))\n",
    "print(\"Number of Benign cases: {0} ({1:2.2f}%)\".format(num_false, (float(num_false)/num_obs) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_col_names = ['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']\n",
    "predicted_class_names = ['diagnosis']\n",
    "X = df[feature_col_names].values     \n",
    "y = df[predicted_class_names].values \n",
    "split_test_size = 0.30 #That is use 30% data as test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_test_size, random_state=42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Upendra\\AppData\\Local\\conda\\conda\\envs\\DeepLearningEnv\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, input_dim=30, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\Upendra\\AppData\\Local\\conda\\conda\\envs\\DeepLearningEnv\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=30, init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(1, init='uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21000 samples, validate on 9000 samples\n",
      "Epoch 1/600\n",
      " - 0s - loss: 0.1257 - acc: 0.8462 - val_loss: 0.0604 - val_acc: 0.9211\n",
      "Epoch 2/600\n",
      " - 0s - loss: 0.0605 - acc: 0.9217 - val_loss: 0.0585 - val_acc: 0.9259\n",
      "Epoch 3/600\n",
      " - 0s - loss: 0.0576 - acc: 0.9250 - val_loss: 0.0509 - val_acc: 0.9308\n",
      "Epoch 4/600\n",
      " - 0s - loss: 0.0541 - acc: 0.9276 - val_loss: 0.0481 - val_acc: 0.9340\n",
      "Epoch 5/600\n",
      " - 0s - loss: 0.0483 - acc: 0.9344 - val_loss: 0.0506 - val_acc: 0.9299\n",
      "Epoch 6/600\n",
      " - 0s - loss: 0.0460 - acc: 0.9390 - val_loss: 0.0434 - val_acc: 0.9421\n",
      "Epoch 7/600\n",
      " - 0s - loss: 0.0418 - acc: 0.9450 - val_loss: 0.0590 - val_acc: 0.9204\n",
      "Epoch 8/600\n",
      " - 0s - loss: 0.0433 - acc: 0.9402 - val_loss: 0.0692 - val_acc: 0.9167\n",
      "Epoch 9/600\n",
      " - 0s - loss: 0.0461 - acc: 0.9389 - val_loss: 0.0384 - val_acc: 0.9472\n",
      "Epoch 10/600\n",
      " - 0s - loss: 0.0366 - acc: 0.9495 - val_loss: 0.0481 - val_acc: 0.9353\n",
      "Epoch 11/600\n",
      " - 0s - loss: 0.0380 - acc: 0.9497 - val_loss: 0.0391 - val_acc: 0.9481\n",
      "Epoch 12/600\n",
      " - 0s - loss: 0.0340 - acc: 0.9545 - val_loss: 0.0848 - val_acc: 0.9000\n",
      "Epoch 13/600\n",
      " - 0s - loss: 0.0383 - acc: 0.9481 - val_loss: 0.0337 - val_acc: 0.9528\n",
      "Epoch 14/600\n",
      " - 0s - loss: 0.0320 - acc: 0.9584 - val_loss: 0.0902 - val_acc: 0.8862\n",
      "Epoch 15/600\n",
      " - 0s - loss: 0.0415 - acc: 0.9453 - val_loss: 0.0380 - val_acc: 0.9583\n",
      "Epoch 16/600\n",
      " - 0s - loss: 0.0305 - acc: 0.9597 - val_loss: 0.0416 - val_acc: 0.9561\n",
      "Epoch 17/600\n",
      " - 0s - loss: 0.0359 - acc: 0.9560 - val_loss: 0.0686 - val_acc: 0.9094\n",
      "Epoch 18/600\n",
      " - 0s - loss: 0.0393 - acc: 0.9497 - val_loss: 0.0332 - val_acc: 0.9603\n",
      "Epoch 19/600\n",
      " - 0s - loss: 0.0272 - acc: 0.9621 - val_loss: 0.0356 - val_acc: 0.9638\n",
      "Epoch 20/600\n",
      " - 0s - loss: 0.0286 - acc: 0.9622 - val_loss: 0.2104 - val_acc: 0.7458\n",
      "Epoch 21/600\n",
      " - 0s - loss: 0.0526 - acc: 0.9327 - val_loss: 0.0363 - val_acc: 0.9527\n",
      "Epoch 22/600\n",
      " - 0s - loss: 0.0324 - acc: 0.9558 - val_loss: 0.0450 - val_acc: 0.9482\n",
      "Epoch 23/600\n",
      " - 0s - loss: 0.0311 - acc: 0.9575 - val_loss: 0.0364 - val_acc: 0.9578\n",
      "Epoch 24/600\n",
      " - 0s - loss: 0.0314 - acc: 0.9581 - val_loss: 0.0277 - val_acc: 0.9581\n",
      "Epoch 25/600\n",
      " - 0s - loss: 0.0267 - acc: 0.9625 - val_loss: 0.0341 - val_acc: 0.9618\n",
      "Epoch 26/600\n",
      " - 0s - loss: 0.0291 - acc: 0.9615 - val_loss: 0.0641 - val_acc: 0.9123\n",
      "Epoch 27/600\n",
      " - 0s - loss: 0.0311 - acc: 0.9610 - val_loss: 0.0506 - val_acc: 0.9384\n",
      "Epoch 28/600\n",
      " - 0s - loss: 0.0297 - acc: 0.9619 - val_loss: 0.0258 - val_acc: 0.9606\n",
      "Epoch 29/600\n",
      " - 0s - loss: 0.0249 - acc: 0.9673 - val_loss: 0.0599 - val_acc: 0.9201\n",
      "Epoch 30/600\n",
      " - 0s - loss: 0.0286 - acc: 0.9630 - val_loss: 0.0243 - val_acc: 0.9642\n",
      "Epoch 31/600\n",
      " - 0s - loss: 0.0236 - acc: 0.9676 - val_loss: 0.0511 - val_acc: 0.9397\n",
      "Epoch 32/600\n",
      " - 0s - loss: 0.0280 - acc: 0.9653 - val_loss: 0.0233 - val_acc: 0.9646\n",
      "Epoch 33/600\n",
      " - 0s - loss: 0.0235 - acc: 0.9698 - val_loss: 0.0346 - val_acc: 0.9572\n",
      "Epoch 34/600\n",
      " - 0s - loss: 0.0237 - acc: 0.9686 - val_loss: 0.0272 - val_acc: 0.9691\n",
      "Epoch 35/600\n",
      " - 0s - loss: 0.0221 - acc: 0.9736 - val_loss: 0.0542 - val_acc: 0.9302\n",
      "Epoch 36/600\n",
      " - 0s - loss: 0.0351 - acc: 0.9556 - val_loss: 0.0330 - val_acc: 0.9637\n",
      "Epoch 37/600\n",
      " - 0s - loss: 0.0244 - acc: 0.9672 - val_loss: 0.0258 - val_acc: 0.9648\n",
      "Epoch 38/600\n",
      " - 0s - loss: 0.0240 - acc: 0.9680 - val_loss: 0.0380 - val_acc: 0.9572\n",
      "Epoch 39/600\n",
      " - 0s - loss: 0.0266 - acc: 0.9647 - val_loss: 0.0268 - val_acc: 0.9631\n",
      "Epoch 40/600\n",
      " - 0s - loss: 0.0260 - acc: 0.9658 - val_loss: 0.0250 - val_acc: 0.9627\n",
      "Epoch 41/600\n",
      " - 0s - loss: 0.0249 - acc: 0.9669 - val_loss: 0.0388 - val_acc: 0.9572\n",
      "Epoch 42/600\n",
      " - 0s - loss: 0.0246 - acc: 0.9678 - val_loss: 0.0249 - val_acc: 0.9647\n",
      "Epoch 43/600\n",
      " - 0s - loss: 0.0228 - acc: 0.9688 - val_loss: 0.0335 - val_acc: 0.9626\n",
      "Epoch 44/600\n",
      " - 0s - loss: 0.0234 - acc: 0.9701 - val_loss: 0.0260 - val_acc: 0.9689\n",
      "Epoch 45/600\n",
      " - 0s - loss: 0.0241 - acc: 0.9694 - val_loss: 0.0336 - val_acc: 0.9639\n",
      "Epoch 46/600\n",
      " - 0s - loss: 0.0232 - acc: 0.9709 - val_loss: 0.0227 - val_acc: 0.9683\n",
      "Epoch 47/600\n",
      " - 0s - loss: 0.0227 - acc: 0.9706 - val_loss: 0.0216 - val_acc: 0.9758\n",
      "Epoch 48/600\n",
      " - 0s - loss: 0.0211 - acc: 0.9745 - val_loss: 0.0212 - val_acc: 0.9751\n",
      "Epoch 49/600\n",
      " - 0s - loss: 0.0209 - acc: 0.9735 - val_loss: 0.0351 - val_acc: 0.9587\n",
      "Epoch 50/600\n",
      " - 0s - loss: 0.0241 - acc: 0.9680 - val_loss: 0.0222 - val_acc: 0.9664\n",
      "Epoch 51/600\n",
      " - 0s - loss: 0.0218 - acc: 0.9709 - val_loss: 0.0451 - val_acc: 0.9417\n",
      "Epoch 52/600\n",
      " - 0s - loss: 0.0247 - acc: 0.9690 - val_loss: 0.0212 - val_acc: 0.9766\n",
      "Epoch 53/600\n",
      " - 0s - loss: 0.0207 - acc: 0.9748 - val_loss: 0.0211 - val_acc: 0.9691\n",
      "Epoch 54/600\n",
      " - 0s - loss: 0.0200 - acc: 0.9760 - val_loss: 0.0314 - val_acc: 0.9640\n",
      "Epoch 55/600\n",
      " - 0s - loss: 0.0216 - acc: 0.9735 - val_loss: 0.0696 - val_acc: 0.9044\n",
      "Epoch 56/600\n",
      " - 0s - loss: 0.0327 - acc: 0.9578 - val_loss: 0.0424 - val_acc: 0.9494\n",
      "Epoch 57/600\n",
      " - 0s - loss: 0.0265 - acc: 0.9655 - val_loss: 0.0224 - val_acc: 0.9724\n",
      "Epoch 58/600\n",
      " - 0s - loss: 0.0227 - acc: 0.9697 - val_loss: 0.0229 - val_acc: 0.9692\n",
      "Epoch 59/600\n",
      " - 0s - loss: 0.0235 - acc: 0.9696 - val_loss: 0.0238 - val_acc: 0.9666\n",
      "Epoch 60/600\n",
      " - 0s - loss: 0.0216 - acc: 0.9727 - val_loss: 0.0215 - val_acc: 0.9721\n",
      "Epoch 61/600\n",
      " - 0s - loss: 0.0221 - acc: 0.9703 - val_loss: 0.0258 - val_acc: 0.9601\n",
      "Epoch 62/600\n",
      " - 0s - loss: 0.0220 - acc: 0.9710 - val_loss: 0.0224 - val_acc: 0.9724\n",
      "Epoch 63/600\n",
      " - 0s - loss: 0.0224 - acc: 0.9707 - val_loss: 0.0213 - val_acc: 0.9708\n",
      "Epoch 64/600\n",
      " - 0s - loss: 0.0216 - acc: 0.9708 - val_loss: 0.0217 - val_acc: 0.9753\n",
      "Epoch 65/600\n",
      " - 0s - loss: 0.0217 - acc: 0.9712 - val_loss: 0.0212 - val_acc: 0.9734\n",
      "Epoch 66/600\n",
      " - 0s - loss: 0.0233 - acc: 0.9703 - val_loss: 0.0377 - val_acc: 0.9603\n",
      "Epoch 67/600\n",
      " - 0s - loss: 0.0221 - acc: 0.9710 - val_loss: 0.0220 - val_acc: 0.9676\n",
      "Epoch 68/600\n",
      " - 0s - loss: 0.0205 - acc: 0.9735 - val_loss: 0.0493 - val_acc: 0.9444\n",
      "Epoch 69/600\n",
      " - 0s - loss: 0.0275 - acc: 0.9649 - val_loss: 0.0676 - val_acc: 0.9169\n",
      "Epoch 70/600\n",
      " - 0s - loss: 0.0309 - acc: 0.9620 - val_loss: 0.0329 - val_acc: 0.9603\n",
      "Epoch 71/600\n",
      " - 0s - loss: 0.0240 - acc: 0.9698 - val_loss: 0.0444 - val_acc: 0.9412\n",
      "Epoch 72/600\n",
      " - 0s - loss: 0.0263 - acc: 0.9651 - val_loss: 0.0218 - val_acc: 0.9676\n",
      "Epoch 73/600\n",
      " - 0s - loss: 0.0234 - acc: 0.9694 - val_loss: 0.0209 - val_acc: 0.9678\n",
      "Epoch 74/600\n",
      " - 0s - loss: 0.0207 - acc: 0.9730 - val_loss: 0.0220 - val_acc: 0.9718\n",
      "Epoch 75/600\n",
      " - 0s - loss: 0.0202 - acc: 0.9747 - val_loss: 0.0205 - val_acc: 0.9756\n",
      "Epoch 76/600\n",
      " - 0s - loss: 0.0210 - acc: 0.9729 - val_loss: 0.0219 - val_acc: 0.9690\n",
      "Epoch 77/600\n",
      " - 0s - loss: 0.0199 - acc: 0.9740 - val_loss: 0.0209 - val_acc: 0.9710\n",
      "Epoch 78/600\n",
      " - 0s - loss: 0.0209 - acc: 0.9735 - val_loss: 0.0312 - val_acc: 0.9641\n",
      "Epoch 79/600\n",
      " - 0s - loss: 0.0223 - acc: 0.9722 - val_loss: 0.0786 - val_acc: 0.8959\n",
      "Epoch 80/600\n",
      " - 0s - loss: 0.0274 - acc: 0.9655 - val_loss: 0.0216 - val_acc: 0.9676\n",
      "Epoch 81/600\n",
      " - 0s - loss: 0.0201 - acc: 0.9754 - val_loss: 0.0219 - val_acc: 0.9753\n",
      "Epoch 82/600\n",
      " - 0s - loss: 0.0209 - acc: 0.9731 - val_loss: 0.0254 - val_acc: 0.9617\n",
      "Epoch 83/600\n",
      " - 0s - loss: 0.0215 - acc: 0.9732 - val_loss: 0.0213 - val_acc: 0.9749\n",
      "Epoch 84/600\n",
      " - 0s - loss: 0.0197 - acc: 0.9746 - val_loss: 0.0220 - val_acc: 0.9739\n",
      "Epoch 85/600\n",
      " - 0s - loss: 0.0205 - acc: 0.9752 - val_loss: 0.0705 - val_acc: 0.9069\n",
      "Epoch 86/600\n",
      " - 0s - loss: 0.0337 - acc: 0.9577 - val_loss: 0.0696 - val_acc: 0.9026\n",
      "Epoch 87/600\n",
      " - 0s - loss: 0.0280 - acc: 0.9643 - val_loss: 0.0273 - val_acc: 0.9668\n",
      "Epoch 88/600\n",
      " - 0s - loss: 0.0206 - acc: 0.9739 - val_loss: 0.0369 - val_acc: 0.9529\n",
      "Epoch 89/600\n",
      " - 0s - loss: 0.0237 - acc: 0.9697 - val_loss: 0.0583 - val_acc: 0.9173\n",
      "Epoch 90/600\n",
      " - 0s - loss: 0.0310 - acc: 0.9604 - val_loss: 0.0282 - val_acc: 0.9634\n",
      "Epoch 91/600\n",
      " - 0s - loss: 0.0225 - acc: 0.9700 - val_loss: 0.0208 - val_acc: 0.9689\n",
      "Epoch 92/600\n",
      " - 0s - loss: 0.0202 - acc: 0.9732 - val_loss: 0.0221 - val_acc: 0.9666\n",
      "Epoch 93/600\n",
      " - 0s - loss: 0.0192 - acc: 0.9755 - val_loss: 0.0205 - val_acc: 0.9690\n",
      "Epoch 94/600\n",
      " - 0s - loss: 0.0195 - acc: 0.9754 - val_loss: 0.0348 - val_acc: 0.9580\n",
      "Epoch 95/600\n",
      " - 0s - loss: 0.0226 - acc: 0.9726 - val_loss: 0.0374 - val_acc: 0.9564\n",
      "Epoch 96/600\n",
      " - 0s - loss: 0.0239 - acc: 0.9699 - val_loss: 0.0252 - val_acc: 0.9706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/600\n",
      " - 0s - loss: 0.0217 - acc: 0.9740 - val_loss: 0.0239 - val_acc: 0.9704\n",
      "Epoch 98/600\n",
      " - 0s - loss: 0.0216 - acc: 0.9748 - val_loss: 0.0735 - val_acc: 0.8988\n",
      "Epoch 99/600\n",
      " - 0s - loss: 0.0286 - acc: 0.9660 - val_loss: 0.0203 - val_acc: 0.9723\n",
      "Epoch 100/600\n",
      " - 0s - loss: 0.0210 - acc: 0.9749 - val_loss: 0.0276 - val_acc: 0.9648\n",
      "Epoch 101/600\n",
      " - 0s - loss: 0.0200 - acc: 0.9773 - val_loss: 0.1111 - val_acc: 0.8657\n",
      "Epoch 102/600\n",
      " - 0s - loss: 0.0288 - acc: 0.9636 - val_loss: 0.0599 - val_acc: 0.9162\n",
      "Epoch 103/600\n",
      " - 0s - loss: 0.0261 - acc: 0.9663 - val_loss: 0.0244 - val_acc: 0.9668\n",
      "Epoch 104/600\n",
      " - 0s - loss: 0.0205 - acc: 0.9726 - val_loss: 0.0228 - val_acc: 0.9686\n",
      "Epoch 105/600\n",
      " - 0s - loss: 0.0195 - acc: 0.9755 - val_loss: 0.0194 - val_acc: 0.9734\n",
      "Epoch 106/600\n",
      " - 0s - loss: 0.0193 - acc: 0.9747 - val_loss: 0.0500 - val_acc: 0.9343\n",
      "Epoch 107/600\n",
      " - 0s - loss: 0.0224 - acc: 0.9740 - val_loss: 0.0198 - val_acc: 0.9783\n",
      "Epoch 108/600\n",
      " - 0s - loss: 0.0195 - acc: 0.9755 - val_loss: 0.0190 - val_acc: 0.9748\n",
      "Epoch 109/600\n",
      " - 0s - loss: 0.0193 - acc: 0.9780 - val_loss: 0.0612 - val_acc: 0.9292\n",
      "Epoch 110/600\n",
      " - 0s - loss: 0.0263 - acc: 0.9677 - val_loss: 0.0219 - val_acc: 0.9712\n",
      "Epoch 111/600\n",
      " - 0s - loss: 0.0200 - acc: 0.9768 - val_loss: 0.0331 - val_acc: 0.9626\n",
      "Epoch 112/600\n",
      " - 0s - loss: 0.0224 - acc: 0.9726 - val_loss: 0.0201 - val_acc: 0.9738\n",
      "Epoch 113/600\n",
      " - 0s - loss: 0.0194 - acc: 0.9778 - val_loss: 0.0258 - val_acc: 0.9683\n",
      "Epoch 114/600\n",
      " - 0s - loss: 0.0207 - acc: 0.9747 - val_loss: 0.0288 - val_acc: 0.9680\n",
      "Epoch 115/600\n",
      " - 0s - loss: 0.0209 - acc: 0.9755 - val_loss: 0.0227 - val_acc: 0.9711\n",
      "Epoch 116/600\n",
      " - 0s - loss: 0.0183 - acc: 0.9780 - val_loss: 0.0267 - val_acc: 0.9689\n",
      "Epoch 117/600\n",
      " - 0s - loss: 0.0187 - acc: 0.9773 - val_loss: 0.0182 - val_acc: 0.9813\n",
      "Epoch 118/600\n",
      " - 0s - loss: 0.0177 - acc: 0.9781 - val_loss: 0.0244 - val_acc: 0.9648\n",
      "Epoch 119/600\n",
      " - 0s - loss: 0.0178 - acc: 0.9800 - val_loss: 0.0180 - val_acc: 0.9806\n",
      "Epoch 120/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9815 - val_loss: 0.0176 - val_acc: 0.9781\n",
      "Epoch 121/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9795 - val_loss: 0.0210 - val_acc: 0.9713\n",
      "Epoch 122/600\n",
      " - 0s - loss: 0.0184 - acc: 0.9784 - val_loss: 0.0430 - val_acc: 0.9468\n",
      "Epoch 123/600\n",
      " - 0s - loss: 0.0290 - acc: 0.9659 - val_loss: 0.0660 - val_acc: 0.9114\n",
      "Epoch 124/600\n",
      " - 0s - loss: 0.0249 - acc: 0.9698 - val_loss: 0.0195 - val_acc: 0.9799\n",
      "Epoch 125/600\n",
      " - 0s - loss: 0.0191 - acc: 0.9775 - val_loss: 0.0190 - val_acc: 0.9827\n",
      "Epoch 126/600\n",
      " - 0s - loss: 0.0195 - acc: 0.9769 - val_loss: 0.0189 - val_acc: 0.9789\n",
      "Epoch 127/600\n",
      " - 0s - loss: 0.0193 - acc: 0.9776 - val_loss: 0.0178 - val_acc: 0.9771\n",
      "Epoch 128/600\n",
      " - 0s - loss: 0.0192 - acc: 0.9770 - val_loss: 0.0198 - val_acc: 0.9727\n",
      "Epoch 129/600\n",
      " - 0s - loss: 0.0176 - acc: 0.9796 - val_loss: 0.0188 - val_acc: 0.9749\n",
      "Epoch 130/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9804 - val_loss: 0.0181 - val_acc: 0.9754\n",
      "Epoch 131/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9812 - val_loss: 0.0340 - val_acc: 0.9594\n",
      "Epoch 132/600\n",
      " - 0s - loss: 0.0189 - acc: 0.9776 - val_loss: 0.0199 - val_acc: 0.9682\n",
      "Epoch 133/600\n",
      " - 0s - loss: 0.0170 - acc: 0.9806 - val_loss: 0.0171 - val_acc: 0.9767\n",
      "Epoch 134/600\n",
      " - 0s - loss: 0.0192 - acc: 0.9769 - val_loss: 0.0186 - val_acc: 0.9793\n",
      "Epoch 135/600\n",
      " - 0s - loss: 0.0185 - acc: 0.9776 - val_loss: 0.0293 - val_acc: 0.9666\n",
      "Epoch 136/600\n",
      " - 0s - loss: 0.0196 - acc: 0.9762 - val_loss: 0.0172 - val_acc: 0.9787\n",
      "Epoch 137/600\n",
      " - 0s - loss: 0.0183 - acc: 0.9779 - val_loss: 0.0172 - val_acc: 0.9809\n",
      "Epoch 138/600\n",
      " - 0s - loss: 0.0176 - acc: 0.9800 - val_loss: 0.0512 - val_acc: 0.9430\n",
      "Epoch 139/600\n",
      " - 0s - loss: 0.0254 - acc: 0.9693 - val_loss: 0.0583 - val_acc: 0.9274\n",
      "Epoch 140/600\n",
      " - 0s - loss: 0.0278 - acc: 0.9639 - val_loss: 0.0280 - val_acc: 0.9612\n",
      "Epoch 141/600\n",
      " - 0s - loss: 0.0193 - acc: 0.9762 - val_loss: 0.0198 - val_acc: 0.9767\n",
      "Epoch 142/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9807 - val_loss: 0.0506 - val_acc: 0.9302\n",
      "Epoch 143/600\n",
      " - 0s - loss: 0.0260 - acc: 0.9669 - val_loss: 0.0383 - val_acc: 0.9544\n",
      "Epoch 144/600\n",
      " - 0s - loss: 0.0270 - acc: 0.9670 - val_loss: 0.0282 - val_acc: 0.9603\n",
      "Epoch 145/600\n",
      " - 0s - loss: 0.0206 - acc: 0.9746 - val_loss: 0.0256 - val_acc: 0.9691\n",
      "Epoch 146/600\n",
      " - 0s - loss: 0.0198 - acc: 0.9743 - val_loss: 0.0186 - val_acc: 0.9758\n",
      "Epoch 147/600\n",
      " - 0s - loss: 0.0182 - acc: 0.9779 - val_loss: 0.0214 - val_acc: 0.9688\n",
      "Epoch 148/600\n",
      " - 0s - loss: 0.0211 - acc: 0.9723 - val_loss: 0.0205 - val_acc: 0.9730\n",
      "Epoch 149/600\n",
      " - 0s - loss: 0.0191 - acc: 0.9759 - val_loss: 0.0228 - val_acc: 0.9728\n",
      "Epoch 150/600\n",
      " - 0s - loss: 0.0182 - acc: 0.9780 - val_loss: 0.0191 - val_acc: 0.9759\n",
      "Epoch 151/600\n",
      " - 0s - loss: 0.0182 - acc: 0.9782 - val_loss: 0.0221 - val_acc: 0.9732\n",
      "Epoch 152/600\n",
      " - 0s - loss: 0.0202 - acc: 0.9752 - val_loss: 0.0173 - val_acc: 0.9818\n",
      "Epoch 153/600\n",
      " - 0s - loss: 0.0190 - acc: 0.9787 - val_loss: 0.0179 - val_acc: 0.9756\n",
      "Epoch 154/600\n",
      " - 0s - loss: 0.0168 - acc: 0.9839 - val_loss: 0.0344 - val_acc: 0.9581\n",
      "Epoch 155/600\n",
      " - 0s - loss: 0.0194 - acc: 0.9798 - val_loss: 0.0179 - val_acc: 0.9791\n",
      "Epoch 156/600\n",
      " - 0s - loss: 0.0170 - acc: 0.9837 - val_loss: 0.0194 - val_acc: 0.9733\n",
      "Epoch 157/600\n",
      " - 0s - loss: 0.0185 - acc: 0.9780 - val_loss: 0.0249 - val_acc: 0.9674\n",
      "Epoch 158/600\n",
      " - 0s - loss: 0.0181 - acc: 0.9789 - val_loss: 0.0461 - val_acc: 0.9332\n",
      "Epoch 159/600\n",
      " - 0s - loss: 0.0218 - acc: 0.9740 - val_loss: 0.2792 - val_acc: 0.7289\n",
      "Epoch 160/600\n",
      " - 0s - loss: 0.0466 - acc: 0.9476 - val_loss: 0.0232 - val_acc: 0.9768\n",
      "Epoch 161/600\n",
      " - 0s - loss: 0.0204 - acc: 0.9736 - val_loss: 0.0315 - val_acc: 0.9583\n",
      "Epoch 162/600\n",
      " - 0s - loss: 0.0236 - acc: 0.9703 - val_loss: 0.0516 - val_acc: 0.9293\n",
      "Epoch 163/600\n",
      " - 0s - loss: 0.0271 - acc: 0.9662 - val_loss: 0.0199 - val_acc: 0.9736\n",
      "Epoch 164/600\n",
      " - 0s - loss: 0.0193 - acc: 0.9762 - val_loss: 0.0226 - val_acc: 0.9718\n",
      "Epoch 165/600\n",
      " - 0s - loss: 0.0198 - acc: 0.9763 - val_loss: 0.0198 - val_acc: 0.9757\n",
      "Epoch 166/600\n",
      " - 0s - loss: 0.0211 - acc: 0.9736 - val_loss: 0.0319 - val_acc: 0.9641\n",
      "Epoch 167/600\n",
      " - 0s - loss: 0.0215 - acc: 0.9741 - val_loss: 0.0722 - val_acc: 0.9077\n",
      "Epoch 168/600\n",
      " - 0s - loss: 0.0321 - acc: 0.9612 - val_loss: 0.0192 - val_acc: 0.9730\n",
      "Epoch 169/600\n",
      " - 0s - loss: 0.0189 - acc: 0.9786 - val_loss: 0.0220 - val_acc: 0.9718\n",
      "Epoch 170/600\n",
      " - 0s - loss: 0.0193 - acc: 0.9770 - val_loss: 0.0292 - val_acc: 0.9659\n",
      "Epoch 171/600\n",
      " - 0s - loss: 0.0195 - acc: 0.9752 - val_loss: 0.0208 - val_acc: 0.9758\n",
      "Epoch 172/600\n",
      " - 0s - loss: 0.0178 - acc: 0.9784 - val_loss: 0.0199 - val_acc: 0.9750\n",
      "Epoch 173/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9801 - val_loss: 0.0247 - val_acc: 0.9681\n",
      "Epoch 174/600\n",
      " - 0s - loss: 0.0188 - acc: 0.9760 - val_loss: 0.0180 - val_acc: 0.9782\n",
      "Epoch 175/600\n",
      " - 0s - loss: 0.0173 - acc: 0.9792 - val_loss: 0.0174 - val_acc: 0.9781\n",
      "Epoch 176/600\n",
      " - 0s - loss: 0.0181 - acc: 0.9785 - val_loss: 0.0173 - val_acc: 0.9812\n",
      "Epoch 177/600\n",
      " - 0s - loss: 0.0173 - acc: 0.9799 - val_loss: 0.0319 - val_acc: 0.9619\n",
      "Epoch 178/600\n",
      " - 0s - loss: 0.0190 - acc: 0.9764 - val_loss: 0.0170 - val_acc: 0.9761\n",
      "Epoch 179/600\n",
      " - 0s - loss: 0.0171 - acc: 0.9792 - val_loss: 0.0282 - val_acc: 0.9642\n",
      "Epoch 180/600\n",
      " - 0s - loss: 0.0253 - acc: 0.9696 - val_loss: 0.0204 - val_acc: 0.9763\n",
      "Epoch 181/600\n",
      " - 0s - loss: 0.0178 - acc: 0.9794 - val_loss: 0.0177 - val_acc: 0.9750\n",
      "Epoch 182/600\n",
      " - 0s - loss: 0.0191 - acc: 0.9770 - val_loss: 0.0179 - val_acc: 0.9803\n",
      "Epoch 183/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9794 - val_loss: 0.0184 - val_acc: 0.9762\n",
      "Epoch 184/600\n",
      " - 0s - loss: 0.0167 - acc: 0.9827 - val_loss: 0.0163 - val_acc: 0.9804\n",
      "Epoch 185/600\n",
      " - 0s - loss: 0.0181 - acc: 0.9779 - val_loss: 0.0236 - val_acc: 0.9727\n",
      "Epoch 186/600\n",
      " - 0s - loss: 0.0187 - acc: 0.9781 - val_loss: 0.0398 - val_acc: 0.9447\n",
      "Epoch 187/600\n",
      " - 0s - loss: 0.0216 - acc: 0.9749 - val_loss: 0.0174 - val_acc: 0.9813\n",
      "Epoch 188/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9816 - val_loss: 0.0359 - val_acc: 0.9551\n",
      "Epoch 189/600\n",
      " - 0s - loss: 0.0207 - acc: 0.9756 - val_loss: 0.0208 - val_acc: 0.9733\n",
      "Epoch 190/600\n",
      " - 0s - loss: 0.0188 - acc: 0.9784 - val_loss: 0.0195 - val_acc: 0.9719\n",
      "Epoch 191/600\n",
      " - 0s - loss: 0.0175 - acc: 0.9807 - val_loss: 0.0178 - val_acc: 0.9794\n",
      "Epoch 192/600\n",
      " - 0s - loss: 0.0175 - acc: 0.9802 - val_loss: 0.0182 - val_acc: 0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/600\n",
      " - 0s - loss: 0.0191 - acc: 0.9770 - val_loss: 0.0191 - val_acc: 0.9779\n",
      "Epoch 194/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9812 - val_loss: 0.0168 - val_acc: 0.9798\n",
      "Epoch 195/600\n",
      " - 0s - loss: 0.0165 - acc: 0.9808 - val_loss: 0.0643 - val_acc: 0.9266\n",
      "Epoch 196/600\n",
      " - 0s - loss: 0.0283 - acc: 0.9672 - val_loss: 0.0193 - val_acc: 0.9793\n",
      "Epoch 197/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9810 - val_loss: 0.0202 - val_acc: 0.9737\n",
      "Epoch 198/600\n",
      " - 0s - loss: 0.0192 - acc: 0.9776 - val_loss: 0.0248 - val_acc: 0.9690\n",
      "Epoch 199/600\n",
      " - 0s - loss: 0.0180 - acc: 0.9777 - val_loss: 0.0166 - val_acc: 0.9769\n",
      "Epoch 200/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9816 - val_loss: 0.0174 - val_acc: 0.9798\n",
      "Epoch 201/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9801 - val_loss: 0.0172 - val_acc: 0.9818\n",
      "Epoch 202/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9820 - val_loss: 0.0163 - val_acc: 0.9824\n",
      "Epoch 203/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9828 - val_loss: 0.0495 - val_acc: 0.9448\n",
      "Epoch 204/600\n",
      " - 0s - loss: 0.0230 - acc: 0.9735 - val_loss: 0.0179 - val_acc: 0.9791\n",
      "Epoch 205/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9802 - val_loss: 0.0172 - val_acc: 0.9807\n",
      "Epoch 206/600\n",
      " - 0s - loss: 0.0162 - acc: 0.9825 - val_loss: 0.0638 - val_acc: 0.9262\n",
      "Epoch 207/600\n",
      " - 0s - loss: 0.0275 - acc: 0.9670 - val_loss: 0.0740 - val_acc: 0.9120\n",
      "Epoch 208/600\n",
      " - 0s - loss: 0.0267 - acc: 0.9690 - val_loss: 0.0172 - val_acc: 0.9807\n",
      "Epoch 209/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9804 - val_loss: 0.0269 - val_acc: 0.9697\n",
      "Epoch 210/600\n",
      " - 0s - loss: 0.0198 - acc: 0.9766 - val_loss: 0.0167 - val_acc: 0.9776\n",
      "Epoch 211/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9812 - val_loss: 0.0394 - val_acc: 0.9559\n",
      "Epoch 212/600\n",
      " - 0s - loss: 0.0215 - acc: 0.9736 - val_loss: 0.0273 - val_acc: 0.9674\n",
      "Epoch 213/600\n",
      " - 0s - loss: 0.0191 - acc: 0.9781 - val_loss: 0.0227 - val_acc: 0.9754\n",
      "Epoch 214/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9812 - val_loss: 0.0170 - val_acc: 0.9789\n",
      "Epoch 215/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9813 - val_loss: 0.0722 - val_acc: 0.9061\n",
      "Epoch 216/600\n",
      " - 0s - loss: 0.0281 - acc: 0.9666 - val_loss: 0.0176 - val_acc: 0.9829\n",
      "Epoch 217/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9812 - val_loss: 0.0386 - val_acc: 0.9524\n",
      "Epoch 218/600\n",
      " - 0s - loss: 0.0211 - acc: 0.9750 - val_loss: 0.0592 - val_acc: 0.9324\n",
      "Epoch 219/600\n",
      " - 0s - loss: 0.0282 - acc: 0.9674 - val_loss: 0.0279 - val_acc: 0.9651\n",
      "Epoch 220/600\n",
      " - 0s - loss: 0.0216 - acc: 0.9735 - val_loss: 0.0193 - val_acc: 0.9757\n",
      "Epoch 221/600\n",
      " - 0s - loss: 0.0189 - acc: 0.9778 - val_loss: 0.0438 - val_acc: 0.9502\n",
      "Epoch 222/600\n",
      " - 0s - loss: 0.0250 - acc: 0.9711 - val_loss: 0.0261 - val_acc: 0.9722\n",
      "Epoch 223/600\n",
      " - 0s - loss: 0.0199 - acc: 0.9767 - val_loss: 0.0186 - val_acc: 0.9782\n",
      "Epoch 224/600\n",
      " - 0s - loss: 0.0178 - acc: 0.9796 - val_loss: 0.0226 - val_acc: 0.9718\n",
      "Epoch 225/600\n",
      " - 0s - loss: 0.0186 - acc: 0.9796 - val_loss: 0.0720 - val_acc: 0.9053\n",
      "Epoch 226/600\n",
      " - 0s - loss: 0.0280 - acc: 0.9671 - val_loss: 0.0221 - val_acc: 0.9713\n",
      "Epoch 227/600\n",
      " - 0s - loss: 0.0182 - acc: 0.9790 - val_loss: 0.0215 - val_acc: 0.9710\n",
      "Epoch 228/600\n",
      " - 0s - loss: 0.0188 - acc: 0.9782 - val_loss: 0.0202 - val_acc: 0.9752\n",
      "Epoch 229/600\n",
      " - 0s - loss: 0.0185 - acc: 0.9784 - val_loss: 0.0214 - val_acc: 0.9710\n",
      "Epoch 230/600\n",
      " - 0s - loss: 0.0185 - acc: 0.9777 - val_loss: 0.0599 - val_acc: 0.9359\n",
      "Epoch 231/600\n",
      " - 0s - loss: 0.0254 - acc: 0.9703 - val_loss: 0.0183 - val_acc: 0.9772\n",
      "Epoch 232/600\n",
      " - 0s - loss: 0.0173 - acc: 0.9807 - val_loss: 0.0172 - val_acc: 0.9828\n",
      "Epoch 233/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9823 - val_loss: 0.0296 - val_acc: 0.9642\n",
      "Epoch 234/600\n",
      " - 0s - loss: 0.0187 - acc: 0.9786 - val_loss: 0.0208 - val_acc: 0.9697\n",
      "Epoch 235/600\n",
      " - 0s - loss: 0.0176 - acc: 0.9798 - val_loss: 0.0293 - val_acc: 0.9644\n",
      "Epoch 236/600\n",
      " - 0s - loss: 0.0196 - acc: 0.9776 - val_loss: 0.0212 - val_acc: 0.9669\n",
      "Epoch 237/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9816 - val_loss: 0.0539 - val_acc: 0.9337\n",
      "Epoch 238/600\n",
      " - 0s - loss: 0.0264 - acc: 0.9670 - val_loss: 0.0212 - val_acc: 0.9710\n",
      "Epoch 239/600\n",
      " - 0s - loss: 0.0205 - acc: 0.9760 - val_loss: 0.0170 - val_acc: 0.9813\n",
      "Epoch 240/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9844 - val_loss: 0.0167 - val_acc: 0.9789\n",
      "Epoch 241/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9830 - val_loss: 0.0168 - val_acc: 0.9823\n",
      "Epoch 242/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9832 - val_loss: 0.0170 - val_acc: 0.9878\n",
      "Epoch 243/600\n",
      " - 0s - loss: 0.0170 - acc: 0.9816 - val_loss: 0.0194 - val_acc: 0.9739\n",
      "Epoch 244/600\n",
      " - 0s - loss: 0.0186 - acc: 0.9782 - val_loss: 0.0178 - val_acc: 0.9766\n",
      "Epoch 245/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9829 - val_loss: 0.0208 - val_acc: 0.9724\n",
      "Epoch 246/600\n",
      " - 0s - loss: 0.0187 - acc: 0.9766 - val_loss: 0.0169 - val_acc: 0.9806\n",
      "Epoch 247/600\n",
      " - 0s - loss: 0.0165 - acc: 0.9832 - val_loss: 0.0176 - val_acc: 0.9783\n",
      "Epoch 248/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9817 - val_loss: 0.0360 - val_acc: 0.9598\n",
      "Epoch 249/600\n",
      " - 0s - loss: 0.0187 - acc: 0.9794 - val_loss: 0.0249 - val_acc: 0.9691\n",
      "Epoch 250/600\n",
      " - 0s - loss: 0.0215 - acc: 0.9742 - val_loss: 0.0181 - val_acc: 0.9779\n",
      "Epoch 251/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9813 - val_loss: 0.0171 - val_acc: 0.9803\n",
      "Epoch 252/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9862 - val_loss: 0.0164 - val_acc: 0.9818\n",
      "Epoch 253/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9844 - val_loss: 0.0315 - val_acc: 0.9611\n",
      "Epoch 254/600\n",
      " - 0s - loss: 0.0209 - acc: 0.9746 - val_loss: 0.0165 - val_acc: 0.9828\n",
      "Epoch 255/600\n",
      " - 0s - loss: 0.0162 - acc: 0.9841 - val_loss: 0.0535 - val_acc: 0.9353\n",
      "Epoch 256/600\n",
      " - 0s - loss: 0.0238 - acc: 0.9733 - val_loss: 0.0170 - val_acc: 0.9839\n",
      "Epoch 257/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9842 - val_loss: 0.0177 - val_acc: 0.9779\n",
      "Epoch 258/600\n",
      " - 0s - loss: 0.0179 - acc: 0.9791 - val_loss: 0.0200 - val_acc: 0.9718\n",
      "Epoch 259/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9839 - val_loss: 0.0170 - val_acc: 0.9828\n",
      "Epoch 260/600\n",
      " - 0s - loss: 0.0162 - acc: 0.9816 - val_loss: 0.0165 - val_acc: 0.9839\n",
      "Epoch 261/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9810 - val_loss: 0.0179 - val_acc: 0.9786\n",
      "Epoch 262/600\n",
      " - 0s - loss: 0.0162 - acc: 0.9838 - val_loss: 0.0230 - val_acc: 0.9669\n",
      "Epoch 263/600\n",
      " - 0s - loss: 0.0177 - acc: 0.9812 - val_loss: 0.0207 - val_acc: 0.9737\n",
      "Epoch 264/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9833 - val_loss: 0.0159 - val_acc: 0.9839\n",
      "Epoch 265/600\n",
      " - 0s - loss: 0.0165 - acc: 0.9817 - val_loss: 0.0221 - val_acc: 0.9691\n",
      "Epoch 266/600\n",
      " - 0s - loss: 0.0182 - acc: 0.9777 - val_loss: 0.0191 - val_acc: 0.9794\n",
      "Epoch 267/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9812 - val_loss: 0.0185 - val_acc: 0.9759\n",
      "Epoch 268/600\n",
      " - 0s - loss: 0.0167 - acc: 0.9827 - val_loss: 0.0178 - val_acc: 0.9800\n",
      "Epoch 269/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9838 - val_loss: 0.0368 - val_acc: 0.9567\n",
      "Epoch 270/600\n",
      " - 0s - loss: 0.0214 - acc: 0.9743 - val_loss: 0.0180 - val_acc: 0.9843\n",
      "Epoch 271/600\n",
      " - 0s - loss: 0.0160 - acc: 0.9858 - val_loss: 0.0188 - val_acc: 0.9794\n",
      "Epoch 272/600\n",
      " - 0s - loss: 0.0156 - acc: 0.9851 - val_loss: 0.0212 - val_acc: 0.9690\n",
      "Epoch 273/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9818 - val_loss: 0.0164 - val_acc: 0.9828\n",
      "Epoch 274/600\n",
      " - 0s - loss: 0.0155 - acc: 0.9857 - val_loss: 0.0161 - val_acc: 0.9811\n",
      "Epoch 275/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9848 - val_loss: 0.0176 - val_acc: 0.9777\n",
      "Epoch 276/600\n",
      " - 0s - loss: 0.0156 - acc: 0.9848 - val_loss: 0.0166 - val_acc: 0.9828\n",
      "Epoch 277/600\n",
      " - 0s - loss: 0.0160 - acc: 0.9828 - val_loss: 0.0163 - val_acc: 0.9827\n",
      "Epoch 278/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9843 - val_loss: 0.0220 - val_acc: 0.9647\n",
      "Epoch 279/600\n",
      " - 0s - loss: 0.0185 - acc: 0.9793 - val_loss: 0.0174 - val_acc: 0.9759\n",
      "Epoch 280/600\n",
      " - 0s - loss: 0.0156 - acc: 0.9851 - val_loss: 0.0181 - val_acc: 0.9751\n",
      "Epoch 281/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9834 - val_loss: 0.0179 - val_acc: 0.9806\n",
      "Epoch 282/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9833 - val_loss: 0.0180 - val_acc: 0.9809\n",
      "Epoch 283/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9822 - val_loss: 0.0187 - val_acc: 0.9777\n",
      "Epoch 284/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9825 - val_loss: 0.0353 - val_acc: 0.9583\n",
      "Epoch 285/600\n",
      " - 0s - loss: 0.0247 - acc: 0.9708 - val_loss: 0.0352 - val_acc: 0.9581\n",
      "Epoch 286/600\n",
      " - 0s - loss: 0.0210 - acc: 0.9799 - val_loss: 0.0189 - val_acc: 0.9861\n",
      "Epoch 287/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9831 - val_loss: 0.0201 - val_acc: 0.9794\n",
      "Epoch 288/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9859 - val_loss: 0.0491 - val_acc: 0.9476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/600\n",
      " - 0s - loss: 0.0205 - acc: 0.9781 - val_loss: 0.0156 - val_acc: 0.9813\n",
      "Epoch 290/600\n",
      " - 0s - loss: 0.0165 - acc: 0.9816 - val_loss: 0.0248 - val_acc: 0.9709\n",
      "Epoch 291/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9814 - val_loss: 0.0224 - val_acc: 0.9668\n",
      "Epoch 292/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9837 - val_loss: 0.0168 - val_acc: 0.9814\n",
      "Epoch 293/600\n",
      " - 0s - loss: 0.0160 - acc: 0.9820 - val_loss: 0.0163 - val_acc: 0.9813\n",
      "Epoch 294/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9854 - val_loss: 0.0197 - val_acc: 0.9790\n",
      "Epoch 295/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9810 - val_loss: 0.0251 - val_acc: 0.9651\n",
      "Epoch 296/600\n",
      " - 0s - loss: 0.0167 - acc: 0.9821 - val_loss: 0.0165 - val_acc: 0.9828\n",
      "Epoch 297/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9844 - val_loss: 0.1842 - val_acc: 0.8203\n",
      "Epoch 298/600\n",
      " - 0s - loss: 0.0567 - acc: 0.9310 - val_loss: 0.0207 - val_acc: 0.9718\n",
      "Epoch 299/600\n",
      " - 0s - loss: 0.0180 - acc: 0.9795 - val_loss: 0.0186 - val_acc: 0.9756\n",
      "Epoch 300/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9799 - val_loss: 0.0236 - val_acc: 0.9702\n",
      "Epoch 301/600\n",
      " - 0s - loss: 0.0177 - acc: 0.9793 - val_loss: 0.0350 - val_acc: 0.9607\n",
      "Epoch 302/600\n",
      " - 0s - loss: 0.0223 - acc: 0.9748 - val_loss: 0.0189 - val_acc: 0.9722\n",
      "Epoch 303/600\n",
      " - 0s - loss: 0.0167 - acc: 0.9814 - val_loss: 0.0177 - val_acc: 0.9802\n",
      "Epoch 304/600\n",
      " - 0s - loss: 0.0176 - acc: 0.9809 - val_loss: 0.0278 - val_acc: 0.9672\n",
      "Epoch 305/600\n",
      " - 0s - loss: 0.0193 - acc: 0.9764 - val_loss: 0.0178 - val_acc: 0.9817\n",
      "Epoch 306/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9809 - val_loss: 0.0168 - val_acc: 0.9781\n",
      "Epoch 307/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9800 - val_loss: 0.0421 - val_acc: 0.9524\n",
      "Epoch 308/600\n",
      " - 0s - loss: 0.0237 - acc: 0.9718 - val_loss: 0.0199 - val_acc: 0.9701\n",
      "Epoch 309/600\n",
      " - 0s - loss: 0.0185 - acc: 0.9787 - val_loss: 0.0186 - val_acc: 0.9722\n",
      "Epoch 310/600\n",
      " - 0s - loss: 0.0173 - acc: 0.9828 - val_loss: 0.0343 - val_acc: 0.9620\n",
      "Epoch 311/600\n",
      " - 0s - loss: 0.0226 - acc: 0.9732 - val_loss: 0.0197 - val_acc: 0.9749\n",
      "Epoch 312/600\n",
      " - 0s - loss: 0.0180 - acc: 0.9796 - val_loss: 0.0235 - val_acc: 0.9732\n",
      "Epoch 313/600\n",
      " - 0s - loss: 0.0189 - acc: 0.9779 - val_loss: 0.0162 - val_acc: 0.9843\n",
      "Epoch 314/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9825 - val_loss: 0.0175 - val_acc: 0.9840\n",
      "Epoch 315/600\n",
      " - 0s - loss: 0.0183 - acc: 0.9785 - val_loss: 0.0168 - val_acc: 0.9801\n",
      "Epoch 316/600\n",
      " - 0s - loss: 0.0165 - acc: 0.9826 - val_loss: 0.0528 - val_acc: 0.9408\n",
      "Epoch 317/600\n",
      " - 0s - loss: 0.0240 - acc: 0.9742 - val_loss: 0.0164 - val_acc: 0.9869\n",
      "Epoch 318/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9848 - val_loss: 0.0172 - val_acc: 0.9814\n",
      "Epoch 319/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9818 - val_loss: 0.0234 - val_acc: 0.9729\n",
      "Epoch 320/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9822 - val_loss: 0.0163 - val_acc: 0.9826\n",
      "Epoch 321/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9842 - val_loss: 0.0167 - val_acc: 0.9852\n",
      "Epoch 322/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9834 - val_loss: 0.0195 - val_acc: 0.9741\n",
      "Epoch 323/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9826 - val_loss: 0.0218 - val_acc: 0.9751\n",
      "Epoch 324/600\n",
      " - 0s - loss: 0.0180 - acc: 0.9786 - val_loss: 0.0171 - val_acc: 0.9803\n",
      "Epoch 325/600\n",
      " - 0s - loss: 0.0182 - acc: 0.9788 - val_loss: 0.0188 - val_acc: 0.9722\n",
      "Epoch 326/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9835 - val_loss: 0.0164 - val_acc: 0.9818\n",
      "Epoch 327/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9852 - val_loss: 0.0363 - val_acc: 0.9544\n",
      "Epoch 328/600\n",
      " - 0s - loss: 0.0216 - acc: 0.9743 - val_loss: 0.0166 - val_acc: 0.9804\n",
      "Epoch 329/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9808 - val_loss: 0.0154 - val_acc: 0.9858\n",
      "Epoch 330/600\n",
      " - 0s - loss: 0.0151 - acc: 0.9848 - val_loss: 0.0165 - val_acc: 0.9864\n",
      "Epoch 331/600\n",
      " - 0s - loss: 0.0161 - acc: 0.9823 - val_loss: 0.0672 - val_acc: 0.9150\n",
      "Epoch 332/600\n",
      " - 0s - loss: 0.0336 - acc: 0.9613 - val_loss: 0.0285 - val_acc: 0.9662\n",
      "Epoch 333/600\n",
      " - 0s - loss: 0.0176 - acc: 0.9806 - val_loss: 0.0176 - val_acc: 0.9818\n",
      "Epoch 334/600\n",
      " - 0s - loss: 0.0160 - acc: 0.9822 - val_loss: 0.0332 - val_acc: 0.9689\n",
      "Epoch 335/600\n",
      " - 0s - loss: 0.0211 - acc: 0.9762 - val_loss: 0.0201 - val_acc: 0.9700\n",
      "Epoch 336/600\n",
      " - 0s - loss: 0.0165 - acc: 0.9823 - val_loss: 0.0173 - val_acc: 0.9742\n",
      "Epoch 337/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9841 - val_loss: 0.0157 - val_acc: 0.9827\n",
      "Epoch 338/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9861 - val_loss: 0.0285 - val_acc: 0.9629\n",
      "Epoch 339/600\n",
      " - 0s - loss: 0.0207 - acc: 0.9752 - val_loss: 0.0288 - val_acc: 0.9672\n",
      "Epoch 340/600\n",
      " - 0s - loss: 0.0222 - acc: 0.9744 - val_loss: 0.0180 - val_acc: 0.9746\n",
      "Epoch 341/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9834 - val_loss: 0.0226 - val_acc: 0.9701\n",
      "Epoch 342/600\n",
      " - 0s - loss: 0.0205 - acc: 0.9766 - val_loss: 0.0191 - val_acc: 0.9724\n",
      "Epoch 343/600\n",
      " - 0s - loss: 0.0179 - acc: 0.9802 - val_loss: 0.0174 - val_acc: 0.9849\n",
      "Epoch 344/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9861 - val_loss: 0.0170 - val_acc: 0.9857\n",
      "Epoch 345/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9819 - val_loss: 0.0183 - val_acc: 0.9760\n",
      "Epoch 346/600\n",
      " - 0s - loss: 0.0168 - acc: 0.9823 - val_loss: 0.0187 - val_acc: 0.9764\n",
      "Epoch 347/600\n",
      " - 0s - loss: 0.0171 - acc: 0.9808 - val_loss: 0.0325 - val_acc: 0.9644\n",
      "Epoch 348/600\n",
      " - 0s - loss: 0.0213 - acc: 0.9773 - val_loss: 0.0177 - val_acc: 0.9803\n",
      "Epoch 349/600\n",
      " - 0s - loss: 0.0160 - acc: 0.9859 - val_loss: 0.0254 - val_acc: 0.9691\n",
      "Epoch 350/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9829 - val_loss: 0.0159 - val_acc: 0.9858\n",
      "Epoch 351/600\n",
      " - 0s - loss: 0.0162 - acc: 0.9840 - val_loss: 0.0160 - val_acc: 0.9861\n",
      "Epoch 352/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9822 - val_loss: 0.0182 - val_acc: 0.9861\n",
      "Epoch 353/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9863 - val_loss: 0.0157 - val_acc: 0.9843\n",
      "Epoch 354/600\n",
      " - 0s - loss: 0.0152 - acc: 0.9872 - val_loss: 0.0244 - val_acc: 0.9670\n",
      "Epoch 355/600\n",
      " - 0s - loss: 0.0201 - acc: 0.9776 - val_loss: 0.0460 - val_acc: 0.9424\n",
      "Epoch 356/600\n",
      " - 0s - loss: 0.0200 - acc: 0.9786 - val_loss: 0.0253 - val_acc: 0.9628\n",
      "Epoch 357/600\n",
      " - 0s - loss: 0.0179 - acc: 0.9815 - val_loss: 0.0155 - val_acc: 0.9902\n",
      "Epoch 358/600\n",
      " - 0s - loss: 0.0162 - acc: 0.9825 - val_loss: 0.0166 - val_acc: 0.9818\n",
      "Epoch 359/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9846 - val_loss: 0.0164 - val_acc: 0.9781\n",
      "Epoch 360/600\n",
      " - 0s - loss: 0.0153 - acc: 0.9865 - val_loss: 0.0173 - val_acc: 0.9758\n",
      "Epoch 361/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9810 - val_loss: 0.0158 - val_acc: 0.9858\n",
      "Epoch 362/600\n",
      " - 0s - loss: 0.0149 - acc: 0.9874 - val_loss: 0.0199 - val_acc: 0.9700\n",
      "Epoch 363/600\n",
      " - 0s - loss: 0.0161 - acc: 0.9842 - val_loss: 0.0155 - val_acc: 0.9886\n",
      "Epoch 364/600\n",
      " - 0s - loss: 0.0151 - acc: 0.9869 - val_loss: 0.0205 - val_acc: 0.9682\n",
      "Epoch 365/600\n",
      " - 0s - loss: 0.0153 - acc: 0.9866 - val_loss: 0.0162 - val_acc: 0.9809\n",
      "Epoch 366/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9847 - val_loss: 0.0152 - val_acc: 0.9858\n",
      "Epoch 367/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9854 - val_loss: 0.0253 - val_acc: 0.9677\n",
      "Epoch 368/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9821 - val_loss: 0.0152 - val_acc: 0.9886\n",
      "Epoch 369/600\n",
      " - 0s - loss: 0.0147 - acc: 0.9873 - val_loss: 0.0154 - val_acc: 0.9841\n",
      "Epoch 370/600\n",
      " - 0s - loss: 0.0150 - acc: 0.9862 - val_loss: 0.0151 - val_acc: 0.9858\n",
      "Epoch 371/600\n",
      " - 0s - loss: 0.0148 - acc: 0.9873 - val_loss: 0.0160 - val_acc: 0.9861\n",
      "Epoch 372/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9839 - val_loss: 0.0159 - val_acc: 0.9847\n",
      "Epoch 373/600\n",
      " - 0s - loss: 0.0181 - acc: 0.9802 - val_loss: 0.0278 - val_acc: 0.9587\n",
      "Epoch 374/600\n",
      " - 0s - loss: 0.0189 - acc: 0.9789 - val_loss: 0.0163 - val_acc: 0.9800\n",
      "Epoch 375/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9838 - val_loss: 0.0147 - val_acc: 0.9862\n",
      "Epoch 376/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9873 - val_loss: 0.0146 - val_acc: 0.9893\n",
      "Epoch 377/600\n",
      " - 0s - loss: 0.0148 - acc: 0.9863 - val_loss: 0.0170 - val_acc: 0.9803\n",
      "Epoch 378/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9839 - val_loss: 0.0156 - val_acc: 0.9862\n",
      "Epoch 379/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9874 - val_loss: 0.0192 - val_acc: 0.9758\n",
      "Epoch 380/600\n",
      " - 0s - loss: 0.0161 - acc: 0.9836 - val_loss: 0.0156 - val_acc: 0.9886\n",
      "Epoch 381/600\n",
      " - 0s - loss: 0.0150 - acc: 0.9855 - val_loss: 0.0156 - val_acc: 0.9886\n",
      "Epoch 382/600\n",
      " - 0s - loss: 0.0145 - acc: 0.9873 - val_loss: 0.0168 - val_acc: 0.9861\n",
      "Epoch 383/600\n",
      " - 0s - loss: 0.0150 - acc: 0.9861 - val_loss: 0.0181 - val_acc: 0.9777\n",
      "Epoch 384/600\n",
      " - 0s - loss: 0.0150 - acc: 0.9855 - val_loss: 0.0235 - val_acc: 0.9702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/600\n",
      " - 0s - loss: 0.0182 - acc: 0.9798 - val_loss: 0.0187 - val_acc: 0.9813\n",
      "Epoch 386/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9871 - val_loss: 0.0159 - val_acc: 0.9861\n",
      "Epoch 387/600\n",
      " - 0s - loss: 0.0149 - acc: 0.9863 - val_loss: 0.0150 - val_acc: 0.9870\n",
      "Epoch 388/600\n",
      " - 0s - loss: 0.0142 - acc: 0.9883 - val_loss: 0.0393 - val_acc: 0.9641\n",
      "Epoch 389/600\n",
      " - 0s - loss: 0.0233 - acc: 0.9755 - val_loss: 0.0190 - val_acc: 0.9829\n",
      "Epoch 390/600\n",
      " - 0s - loss: 0.0167 - acc: 0.9852 - val_loss: 0.0717 - val_acc: 0.9216\n",
      "Epoch 391/600\n",
      " - 0s - loss: 0.0301 - acc: 0.9661 - val_loss: 0.0202 - val_acc: 0.9759\n",
      "Epoch 392/600\n",
      " - 0s - loss: 0.0171 - acc: 0.9838 - val_loss: 0.0183 - val_acc: 0.9893\n",
      "Epoch 393/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9851 - val_loss: 0.0165 - val_acc: 0.9886\n",
      "Epoch 394/600\n",
      " - 0s - loss: 0.0169 - acc: 0.9844 - val_loss: 0.0170 - val_acc: 0.9843\n",
      "Epoch 395/600\n",
      " - 0s - loss: 0.0168 - acc: 0.9849 - val_loss: 0.0299 - val_acc: 0.9620\n",
      "Epoch 396/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9838 - val_loss: 0.0364 - val_acc: 0.9571\n",
      "Epoch 397/600\n",
      " - 0s - loss: 0.0189 - acc: 0.9813 - val_loss: 0.0205 - val_acc: 0.9724\n",
      "Epoch 398/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9847 - val_loss: 0.0177 - val_acc: 0.9772\n",
      "Epoch 399/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9818 - val_loss: 0.0178 - val_acc: 0.9773\n",
      "Epoch 400/600\n",
      " - 0s - loss: 0.0148 - acc: 0.9857 - val_loss: 0.0143 - val_acc: 0.9893\n",
      "Epoch 401/600\n",
      " - 0s - loss: 0.0150 - acc: 0.9850 - val_loss: 0.0142 - val_acc: 0.9862\n",
      "Epoch 402/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9868 - val_loss: 0.0204 - val_acc: 0.9757\n",
      "Epoch 403/600\n",
      " - 0s - loss: 0.0145 - acc: 0.9862 - val_loss: 0.0264 - val_acc: 0.9658\n",
      "Epoch 404/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9844 - val_loss: 0.0183 - val_acc: 0.9731\n",
      "Epoch 405/600\n",
      " - 0s - loss: 0.0191 - acc: 0.9791 - val_loss: 0.0150 - val_acc: 0.9893\n",
      "Epoch 406/600\n",
      " - 0s - loss: 0.0139 - acc: 0.9872 - val_loss: 0.0146 - val_acc: 0.9869\n",
      "Epoch 407/600\n",
      " - 0s - loss: 0.0139 - acc: 0.9883 - val_loss: 0.0151 - val_acc: 0.9820\n",
      "Epoch 408/600\n",
      " - 0s - loss: 0.0152 - acc: 0.9847 - val_loss: 0.0140 - val_acc: 0.9886\n",
      "Epoch 409/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9890 - val_loss: 0.0281 - val_acc: 0.9631\n",
      "Epoch 410/600\n",
      " - 0s - loss: 0.0183 - acc: 0.9807 - val_loss: 0.0210 - val_acc: 0.9722\n",
      "Epoch 411/600\n",
      " - 0s - loss: 0.0145 - acc: 0.9866 - val_loss: 0.0145 - val_acc: 0.9858\n",
      "Epoch 412/600\n",
      " - 0s - loss: 0.0134 - acc: 0.9886 - val_loss: 0.0199 - val_acc: 0.9703\n",
      "Epoch 413/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9817 - val_loss: 0.0155 - val_acc: 0.9820\n",
      "Epoch 414/600\n",
      " - 0s - loss: 0.0145 - acc: 0.9858 - val_loss: 0.0156 - val_acc: 0.9886\n",
      "Epoch 415/600\n",
      " - 0s - loss: 0.0144 - acc: 0.9869 - val_loss: 0.0145 - val_acc: 0.9863\n",
      "Epoch 416/600\n",
      " - 0s - loss: 0.0144 - acc: 0.9869 - val_loss: 0.0188 - val_acc: 0.9811\n",
      "Epoch 417/600\n",
      " - 0s - loss: 0.0150 - acc: 0.9859 - val_loss: 0.0163 - val_acc: 0.9771\n",
      "Epoch 418/600\n",
      " - 0s - loss: 0.0140 - acc: 0.9862 - val_loss: 0.0328 - val_acc: 0.9616\n",
      "Epoch 419/600\n",
      " - 0s - loss: 0.0161 - acc: 0.9840 - val_loss: 0.0157 - val_acc: 0.9861\n",
      "Epoch 420/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9829 - val_loss: 0.0380 - val_acc: 0.9543\n",
      "Epoch 421/600\n",
      " - 0s - loss: 0.0221 - acc: 0.9770 - val_loss: 0.0152 - val_acc: 0.9870\n",
      "Epoch 422/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9881 - val_loss: 0.0147 - val_acc: 0.9803\n",
      "Epoch 423/600\n",
      " - 0s - loss: 0.0155 - acc: 0.9832 - val_loss: 0.0186 - val_acc: 0.9722\n",
      "Epoch 424/600\n",
      " - 0s - loss: 0.0153 - acc: 0.9844 - val_loss: 0.0284 - val_acc: 0.9650\n",
      "Epoch 425/600\n",
      " - 0s - loss: 0.0172 - acc: 0.9824 - val_loss: 0.0144 - val_acc: 0.9893\n",
      "Epoch 426/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9889 - val_loss: 0.0153 - val_acc: 0.9820\n",
      "Epoch 427/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9880 - val_loss: 0.0134 - val_acc: 0.9877\n",
      "Epoch 428/600\n",
      " - 0s - loss: 0.0132 - acc: 0.9890 - val_loss: 0.0230 - val_acc: 0.9686\n",
      "Epoch 429/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9847 - val_loss: 0.0153 - val_acc: 0.9917\n",
      "Epoch 430/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9876 - val_loss: 0.0142 - val_acc: 0.9878\n",
      "Epoch 431/600\n",
      " - 0s - loss: 0.0133 - acc: 0.9891 - val_loss: 0.0289 - val_acc: 0.9672\n",
      "Epoch 432/600\n",
      " - 0s - loss: 0.0164 - acc: 0.9839 - val_loss: 0.0345 - val_acc: 0.9531\n",
      "Epoch 433/600\n",
      " - 0s - loss: 0.0189 - acc: 0.9808 - val_loss: 0.0194 - val_acc: 0.9700\n",
      "Epoch 434/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9881 - val_loss: 0.0135 - val_acc: 0.9893\n",
      "Epoch 435/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9881 - val_loss: 0.0146 - val_acc: 0.9820\n",
      "Epoch 436/600\n",
      " - 0s - loss: 0.0142 - acc: 0.9876 - val_loss: 0.0209 - val_acc: 0.9710\n",
      "Epoch 437/600\n",
      " - 0s - loss: 0.0147 - acc: 0.9868 - val_loss: 0.0142 - val_acc: 0.9886\n",
      "Epoch 438/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9870 - val_loss: 0.0138 - val_acc: 0.9893\n",
      "Epoch 439/600\n",
      " - 0s - loss: 0.0134 - acc: 0.9889 - val_loss: 0.0134 - val_acc: 0.9893\n",
      "Epoch 440/600\n",
      " - 0s - loss: 0.0132 - acc: 0.9896 - val_loss: 0.0272 - val_acc: 0.9630\n",
      "Epoch 441/600\n",
      " - 0s - loss: 0.0190 - acc: 0.9797 - val_loss: 0.0253 - val_acc: 0.9649\n",
      "Epoch 442/600\n",
      " - 0s - loss: 0.0154 - acc: 0.9858 - val_loss: 0.0244 - val_acc: 0.9673\n",
      "Epoch 443/600\n",
      " - 0s - loss: 0.0152 - acc: 0.9855 - val_loss: 0.0163 - val_acc: 0.9871\n",
      "Epoch 444/600\n",
      " - 0s - loss: 0.0145 - acc: 0.9854 - val_loss: 0.0177 - val_acc: 0.9793\n",
      "Epoch 445/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9878 - val_loss: 0.0137 - val_acc: 0.9893\n",
      "Epoch 446/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9878 - val_loss: 0.0137 - val_acc: 0.9869\n",
      "Epoch 447/600\n",
      " - 0s - loss: 0.0140 - acc: 0.9869 - val_loss: 0.0254 - val_acc: 0.9689\n",
      "Epoch 448/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9848 - val_loss: 0.0138 - val_acc: 0.9886\n",
      "Epoch 449/600\n",
      " - 0s - loss: 0.0132 - acc: 0.9891 - val_loss: 0.0148 - val_acc: 0.9850\n",
      "Epoch 450/600\n",
      " - 0s - loss: 0.0147 - acc: 0.9861 - val_loss: 0.0153 - val_acc: 0.9886\n",
      "Epoch 451/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9883 - val_loss: 0.0141 - val_acc: 0.9886\n",
      "Epoch 452/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9858 - val_loss: 0.0141 - val_acc: 0.9886\n",
      "Epoch 453/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9890 - val_loss: 0.0249 - val_acc: 0.9668\n",
      "Epoch 454/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9835 - val_loss: 0.0270 - val_acc: 0.9662\n",
      "Epoch 455/600\n",
      " - 0s - loss: 0.0140 - acc: 0.9867 - val_loss: 0.0245 - val_acc: 0.9696\n",
      "Epoch 456/600\n",
      " - 0s - loss: 0.0185 - acc: 0.9792 - val_loss: 0.0232 - val_acc: 0.9634\n",
      "Epoch 457/600\n",
      " - 0s - loss: 0.0148 - acc: 0.9864 - val_loss: 0.0241 - val_acc: 0.9663\n",
      "Epoch 458/600\n",
      " - 0s - loss: 0.0175 - acc: 0.9795 - val_loss: 0.0147 - val_acc: 0.9834\n",
      "Epoch 459/600\n",
      " - 0s - loss: 0.0128 - acc: 0.9895 - val_loss: 0.0140 - val_acc: 0.9886\n",
      "Epoch 460/600\n",
      " - 0s - loss: 0.0137 - acc: 0.9877 - val_loss: 0.0184 - val_acc: 0.9722\n",
      "Epoch 461/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9884 - val_loss: 0.0139 - val_acc: 0.9858\n",
      "Epoch 462/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9894 - val_loss: 0.0130 - val_acc: 0.9893\n",
      "Epoch 463/600\n",
      " - 0s - loss: 0.0127 - acc: 0.9893 - val_loss: 0.0145 - val_acc: 0.9874\n",
      "Epoch 464/600\n",
      " - 0s - loss: 0.0136 - acc: 0.9882 - val_loss: 0.0327 - val_acc: 0.9608\n",
      "Epoch 465/600\n",
      " - 0s - loss: 0.0178 - acc: 0.9825 - val_loss: 0.0134 - val_acc: 0.9877\n",
      "Epoch 466/600\n",
      " - 0s - loss: 0.0126 - acc: 0.9900 - val_loss: 0.0150 - val_acc: 0.9820\n",
      "Epoch 467/600\n",
      " - 0s - loss: 0.0137 - acc: 0.9873 - val_loss: 0.0154 - val_acc: 0.9847\n",
      "Epoch 468/600\n",
      " - 0s - loss: 0.0141 - acc: 0.9860 - val_loss: 0.0189 - val_acc: 0.9720\n",
      "Epoch 469/600\n",
      " - 0s - loss: 0.0141 - acc: 0.9869 - val_loss: 0.0369 - val_acc: 0.9641\n",
      "Epoch 470/600\n",
      " - 0s - loss: 0.0224 - acc: 0.9797 - val_loss: 0.0156 - val_acc: 0.9800\n",
      "Epoch 471/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9878 - val_loss: 0.0167 - val_acc: 0.9756\n",
      "Epoch 472/600\n",
      " - 0s - loss: 0.0132 - acc: 0.9890 - val_loss: 0.0225 - val_acc: 0.9680\n",
      "Epoch 473/600\n",
      " - 0s - loss: 0.0144 - acc: 0.9875 - val_loss: 0.0133 - val_acc: 0.9827\n",
      "Epoch 474/600\n",
      " - 0s - loss: 0.0127 - acc: 0.9888 - val_loss: 0.0338 - val_acc: 0.9657\n",
      "Epoch 475/600\n",
      " - 0s - loss: 0.0214 - acc: 0.9806 - val_loss: 0.0157 - val_acc: 0.9840\n",
      "Epoch 476/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9877 - val_loss: 0.0148 - val_acc: 0.9801\n",
      "Epoch 477/600\n",
      " - 0s - loss: 0.0131 - acc: 0.9888 - val_loss: 0.0168 - val_acc: 0.9837\n",
      "Epoch 478/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9890 - val_loss: 0.0624 - val_acc: 0.9201\n",
      "Epoch 479/600\n",
      " - 0s - loss: 0.0212 - acc: 0.9782 - val_loss: 0.0182 - val_acc: 0.9742\n",
      "Epoch 480/600\n",
      " - 0s - loss: 0.0134 - acc: 0.9874 - val_loss: 0.0251 - val_acc: 0.9683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/600\n",
      " - 0s - loss: 0.0161 - acc: 0.9830 - val_loss: 0.0177 - val_acc: 0.9847\n",
      "Epoch 482/600\n",
      " - 0s - loss: 0.0144 - acc: 0.9860 - val_loss: 0.0132 - val_acc: 0.9893\n",
      "Epoch 483/600\n",
      " - 0s - loss: 0.0129 - acc: 0.9894 - val_loss: 0.0129 - val_acc: 0.9862\n",
      "Epoch 484/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9898 - val_loss: 0.0308 - val_acc: 0.9641\n",
      "Epoch 485/600\n",
      " - 0s - loss: 0.0177 - acc: 0.9832 - val_loss: 0.0151 - val_acc: 0.9871\n",
      "Epoch 486/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9890 - val_loss: 0.0131 - val_acc: 0.9886\n",
      "Epoch 487/600\n",
      " - 0s - loss: 0.0125 - acc: 0.9898 - val_loss: 0.0266 - val_acc: 0.9651\n",
      "Epoch 488/600\n",
      " - 0s - loss: 0.0174 - acc: 0.9819 - val_loss: 0.0146 - val_acc: 0.9878\n",
      "Epoch 489/600\n",
      " - 0s - loss: 0.0136 - acc: 0.9864 - val_loss: 0.0186 - val_acc: 0.9744\n",
      "Epoch 490/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9878 - val_loss: 0.0146 - val_acc: 0.9886\n",
      "Epoch 491/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9880 - val_loss: 0.0135 - val_acc: 0.9861\n",
      "Epoch 492/600\n",
      " - 0s - loss: 0.0125 - acc: 0.9895 - val_loss: 0.0135 - val_acc: 0.9893\n",
      "Epoch 493/600\n",
      " - 0s - loss: 0.0133 - acc: 0.9879 - val_loss: 0.0128 - val_acc: 0.9893\n",
      "Epoch 494/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9899 - val_loss: 0.0184 - val_acc: 0.9813\n",
      "Epoch 495/600\n",
      " - 0s - loss: 0.0133 - acc: 0.9880 - val_loss: 0.0126 - val_acc: 0.9917\n",
      "Epoch 496/600\n",
      " - 0s - loss: 0.0126 - acc: 0.9897 - val_loss: 0.0513 - val_acc: 0.9464\n",
      "Epoch 497/600\n",
      " - 0s - loss: 0.0180 - acc: 0.9823 - val_loss: 0.0132 - val_acc: 0.9878\n",
      "Epoch 498/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9899 - val_loss: 0.0347 - val_acc: 0.9608\n",
      "Epoch 499/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9850 - val_loss: 0.0144 - val_acc: 0.9886\n",
      "Epoch 500/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9874 - val_loss: 0.0165 - val_acc: 0.9839\n",
      "Epoch 501/600\n",
      " - 0s - loss: 0.0128 - acc: 0.9898 - val_loss: 0.0169 - val_acc: 0.9817\n",
      "Epoch 502/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9884 - val_loss: 0.0130 - val_acc: 0.9893\n",
      "Epoch 503/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9892 - val_loss: 0.0135 - val_acc: 0.9870\n",
      "Epoch 504/600\n",
      " - 0s - loss: 0.0125 - acc: 0.9890 - val_loss: 0.0280 - val_acc: 0.9614\n",
      "Epoch 505/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9831 - val_loss: 0.0129 - val_acc: 0.9893\n",
      "Epoch 506/600\n",
      " - 0s - loss: 0.0121 - acc: 0.9903 - val_loss: 0.0128 - val_acc: 0.9893\n",
      "Epoch 507/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9897 - val_loss: 0.0125 - val_acc: 0.9893\n",
      "Epoch 508/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9898 - val_loss: 0.0314 - val_acc: 0.9602\n",
      "Epoch 509/600\n",
      " - 0s - loss: 0.0180 - acc: 0.9814 - val_loss: 0.0143 - val_acc: 0.9850\n",
      "Epoch 510/600\n",
      " - 0s - loss: 0.0120 - acc: 0.9899 - val_loss: 0.0123 - val_acc: 0.9877\n",
      "Epoch 511/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9892 - val_loss: 0.0128 - val_acc: 0.9917\n",
      "Epoch 512/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9879 - val_loss: 0.0131 - val_acc: 0.9917\n",
      "Epoch 513/600\n",
      " - 0s - loss: 0.0126 - acc: 0.9890 - val_loss: 0.0153 - val_acc: 0.9806\n",
      "Epoch 514/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9898 - val_loss: 0.0149 - val_acc: 0.9820\n",
      "Epoch 515/600\n",
      " - 0s - loss: 0.0140 - acc: 0.9878 - val_loss: 0.0214 - val_acc: 0.9691\n",
      "Epoch 516/600\n",
      " - 0s - loss: 0.0147 - acc: 0.9846 - val_loss: 0.0172 - val_acc: 0.9773\n",
      "Epoch 517/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9891 - val_loss: 0.0120 - val_acc: 0.9900\n",
      "Epoch 518/600\n",
      " - 0s - loss: 0.0117 - acc: 0.9900 - val_loss: 0.0123 - val_acc: 0.9917\n",
      "Epoch 519/600\n",
      " - 0s - loss: 0.0124 - acc: 0.9899 - val_loss: 0.0174 - val_acc: 0.9771\n",
      "Epoch 520/600\n",
      " - 0s - loss: 0.0128 - acc: 0.9881 - val_loss: 0.0124 - val_acc: 0.9893\n",
      "Epoch 521/600\n",
      " - 0s - loss: 0.0117 - acc: 0.9902 - val_loss: 0.0200 - val_acc: 0.9821\n",
      "Epoch 522/600\n",
      " - 0s - loss: 0.0140 - acc: 0.9871 - val_loss: 0.0147 - val_acc: 0.9863\n",
      "Epoch 523/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9889 - val_loss: 0.0131 - val_acc: 0.9886\n",
      "Epoch 524/600\n",
      " - 0s - loss: 0.0120 - acc: 0.9893 - val_loss: 0.0134 - val_acc: 0.9893\n",
      "Epoch 525/600\n",
      " - 0s - loss: 0.0121 - acc: 0.9902 - val_loss: 0.0134 - val_acc: 0.9878\n",
      "Epoch 526/600\n",
      " - 0s - loss: 0.0128 - acc: 0.9890 - val_loss: 0.0367 - val_acc: 0.9593\n",
      "Epoch 527/600\n",
      " - 0s - loss: 0.0166 - acc: 0.9834 - val_loss: 0.0182 - val_acc: 0.9756\n",
      "Epoch 528/600\n",
      " - 0s - loss: 0.0159 - acc: 0.9837 - val_loss: 0.0311 - val_acc: 0.9680\n",
      "Epoch 529/600\n",
      " - 0s - loss: 0.0137 - acc: 0.9871 - val_loss: 0.0152 - val_acc: 0.9861\n",
      "Epoch 530/600\n",
      " - 0s - loss: 0.0119 - acc: 0.9895 - val_loss: 0.0298 - val_acc: 0.9627\n",
      "Epoch 531/600\n",
      " - 0s - loss: 0.0171 - acc: 0.9833 - val_loss: 0.0131 - val_acc: 0.9886\n",
      "Epoch 532/600\n",
      " - 0s - loss: 0.0120 - acc: 0.9904 - val_loss: 0.0130 - val_acc: 0.9858\n",
      "Epoch 533/600\n",
      " - 0s - loss: 0.0139 - acc: 0.9870 - val_loss: 0.0128 - val_acc: 0.9886\n",
      "Epoch 534/600\n",
      " - 0s - loss: 0.0118 - acc: 0.9905 - val_loss: 0.0145 - val_acc: 0.9859\n",
      "Epoch 535/600\n",
      " - 0s - loss: 0.0119 - acc: 0.9894 - val_loss: 0.0126 - val_acc: 0.9893\n",
      "Epoch 536/600\n",
      " - 0s - loss: 0.0121 - acc: 0.9898 - val_loss: 0.0169 - val_acc: 0.9787\n",
      "Epoch 537/600\n",
      " - 0s - loss: 0.0129 - acc: 0.9887 - val_loss: 0.0123 - val_acc: 0.9893\n",
      "Epoch 538/600\n",
      " - 0s - loss: 0.0131 - acc: 0.9876 - val_loss: 0.0287 - val_acc: 0.9650\n",
      "Epoch 539/600\n",
      " - 0s - loss: 0.0157 - acc: 0.9849 - val_loss: 0.0127 - val_acc: 0.9886\n",
      "Epoch 540/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9899 - val_loss: 0.0131 - val_acc: 0.9893\n",
      "Epoch 541/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9895 - val_loss: 0.0124 - val_acc: 0.9886\n",
      "Epoch 542/600\n",
      " - 0s - loss: 0.0120 - acc: 0.9901 - val_loss: 0.0163 - val_acc: 0.9801\n",
      "Epoch 543/600\n",
      " - 0s - loss: 0.0130 - acc: 0.9885 - val_loss: 0.0125 - val_acc: 0.9893\n",
      "Epoch 544/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9896 - val_loss: 0.0165 - val_acc: 0.9792\n",
      "Epoch 545/600\n",
      " - 0s - loss: 0.0120 - acc: 0.9896 - val_loss: 0.0124 - val_acc: 0.9917\n",
      "Epoch 546/600\n",
      " - 0s - loss: 0.0116 - acc: 0.9909 - val_loss: 0.0118 - val_acc: 0.9893\n",
      "Epoch 547/600\n",
      " - 0s - loss: 0.0113 - acc: 0.9906 - val_loss: 0.0130 - val_acc: 0.9878\n",
      "Epoch 548/600\n",
      " - 0s - loss: 0.0147 - acc: 0.9849 - val_loss: 0.0201 - val_acc: 0.9790\n",
      "Epoch 549/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9898 - val_loss: 0.0139 - val_acc: 0.9878\n",
      "Epoch 550/600\n",
      " - 0s - loss: 0.0121 - acc: 0.9898 - val_loss: 0.0189 - val_acc: 0.9700\n",
      "Epoch 551/600\n",
      " - 0s - loss: 0.0127 - acc: 0.9896 - val_loss: 0.0127 - val_acc: 0.9893\n",
      "Epoch 552/600\n",
      " - 0s - loss: 0.0121 - acc: 0.9900 - val_loss: 0.0212 - val_acc: 0.9727\n",
      "Epoch 553/600\n",
      " - 0s - loss: 0.0134 - acc: 0.9877 - val_loss: 0.0125 - val_acc: 0.9917\n",
      "Epoch 554/600\n",
      " - 0s - loss: 0.0121 - acc: 0.9893 - val_loss: 0.0169 - val_acc: 0.9764\n",
      "Epoch 555/600\n",
      " - 0s - loss: 0.0127 - acc: 0.9892 - val_loss: 0.0119 - val_acc: 0.9893\n",
      "Epoch 556/600\n",
      " - 0s - loss: 0.0119 - acc: 0.9903 - val_loss: 0.0328 - val_acc: 0.9670\n",
      "Epoch 557/600\n",
      " - 0s - loss: 0.0181 - acc: 0.9810 - val_loss: 0.0261 - val_acc: 0.9668\n",
      "Epoch 558/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9832 - val_loss: 0.0128 - val_acc: 0.9893\n",
      "Epoch 559/600\n",
      " - 0s - loss: 0.0123 - acc: 0.9894 - val_loss: 0.0161 - val_acc: 0.9821\n",
      "Epoch 560/600\n",
      " - 0s - loss: 0.0134 - acc: 0.9883 - val_loss: 0.0173 - val_acc: 0.9837\n",
      "Epoch 561/600\n",
      " - 0s - loss: 0.0146 - acc: 0.9857 - val_loss: 0.0276 - val_acc: 0.9649\n",
      "Epoch 562/600\n",
      " - 0s - loss: 0.0158 - acc: 0.9861 - val_loss: 0.0239 - val_acc: 0.9694\n",
      "Epoch 563/600\n",
      " - 0s - loss: 0.0136 - acc: 0.9873 - val_loss: 0.0125 - val_acc: 0.9893\n",
      "Epoch 564/600\n",
      " - 0s - loss: 0.0116 - acc: 0.9906 - val_loss: 0.0197 - val_acc: 0.9774\n",
      "Epoch 565/600\n",
      " - 0s - loss: 0.0135 - acc: 0.9873 - val_loss: 0.0140 - val_acc: 0.9834\n",
      "Epoch 566/600\n",
      " - 0s - loss: 0.0115 - acc: 0.9908 - val_loss: 0.0132 - val_acc: 0.9878\n",
      "Epoch 567/600\n",
      " - 0s - loss: 0.0123 - acc: 0.9888 - val_loss: 0.0129 - val_acc: 0.9893\n",
      "Epoch 568/600\n",
      " - 0s - loss: 0.0128 - acc: 0.9889 - val_loss: 0.0145 - val_acc: 0.9861\n",
      "Epoch 569/600\n",
      " - 0s - loss: 0.0133 - acc: 0.9873 - val_loss: 0.0147 - val_acc: 0.9837\n",
      "Epoch 570/600\n",
      " - 0s - loss: 0.0118 - acc: 0.9902 - val_loss: 0.0138 - val_acc: 0.9886\n",
      "Epoch 571/600\n",
      " - 0s - loss: 0.0127 - acc: 0.9880 - val_loss: 0.0120 - val_acc: 0.9900\n",
      "Epoch 572/600\n",
      " - 0s - loss: 0.0125 - acc: 0.9897 - val_loss: 0.0129 - val_acc: 0.9878\n",
      "Epoch 573/600\n",
      " - 0s - loss: 0.0127 - acc: 0.9887 - val_loss: 0.0119 - val_acc: 0.9900\n",
      "Epoch 574/600\n",
      " - 0s - loss: 0.0123 - acc: 0.9895 - val_loss: 0.0188 - val_acc: 0.9837\n",
      "Epoch 575/600\n",
      " - 0s - loss: 0.0128 - acc: 0.9887 - val_loss: 0.0137 - val_acc: 0.9863\n",
      "Epoch 576/600\n",
      " - 0s - loss: 0.0119 - acc: 0.9901 - val_loss: 0.0124 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577/600\n",
      " - 0s - loss: 0.0115 - acc: 0.9903 - val_loss: 0.0118 - val_acc: 0.9917\n",
      "Epoch 578/600\n",
      " - 0s - loss: 0.0114 - acc: 0.9905 - val_loss: 0.0197 - val_acc: 0.9750\n",
      "Epoch 579/600\n",
      " - 0s - loss: 0.0163 - acc: 0.9848 - val_loss: 0.0149 - val_acc: 0.9821\n",
      "Epoch 580/600\n",
      " - 0s - loss: 0.0138 - acc: 0.9871 - val_loss: 0.0191 - val_acc: 0.9821\n",
      "Epoch 581/600\n",
      " - 0s - loss: 0.0122 - acc: 0.9891 - val_loss: 0.0147 - val_acc: 0.9820\n",
      "Epoch 582/600\n",
      " - 0s - loss: 0.0118 - acc: 0.9892 - val_loss: 0.0361 - val_acc: 0.9568\n",
      "Epoch 583/600\n",
      " - 0s - loss: 0.0199 - acc: 0.9790 - val_loss: 0.0119 - val_acc: 0.9893\n",
      "Epoch 584/600\n",
      " - 0s - loss: 0.0113 - acc: 0.9908 - val_loss: 0.0145 - val_acc: 0.9837\n",
      "Epoch 585/600\n",
      " - 0s - loss: 0.0121 - acc: 0.9895 - val_loss: 0.0115 - val_acc: 0.9893\n",
      "Epoch 586/600\n",
      " - 0s - loss: 0.0119 - acc: 0.9897 - val_loss: 0.0201 - val_acc: 0.9733\n",
      "Epoch 587/600\n",
      " - 0s - loss: 0.0137 - acc: 0.9866 - val_loss: 0.0434 - val_acc: 0.9603\n",
      "Epoch 588/600\n",
      " - 0s - loss: 0.0205 - acc: 0.9790 - val_loss: 0.0194 - val_acc: 0.9871\n",
      "Epoch 589/600\n",
      " - 0s - loss: 0.0128 - acc: 0.9903 - val_loss: 0.0125 - val_acc: 0.9917\n",
      "Epoch 590/600\n",
      " - 0s - loss: 0.0132 - acc: 0.9890 - val_loss: 0.0161 - val_acc: 0.9836\n",
      "Epoch 591/600\n",
      " - 0s - loss: 0.0123 - acc: 0.9903 - val_loss: 0.0148 - val_acc: 0.9827\n",
      "Epoch 592/600\n",
      " - 0s - loss: 0.0136 - acc: 0.9884 - val_loss: 0.0135 - val_acc: 0.9861\n",
      "Epoch 593/600\n",
      " - 0s - loss: 0.0120 - acc: 0.9900 - val_loss: 0.0146 - val_acc: 0.9859\n",
      "Epoch 594/600\n",
      " - 0s - loss: 0.0134 - acc: 0.9889 - val_loss: 0.0132 - val_acc: 0.9893\n",
      "Epoch 595/600\n",
      " - 0s - loss: 0.0129 - acc: 0.9906 - val_loss: 0.0133 - val_acc: 0.9893\n",
      "Epoch 596/600\n",
      " - 0s - loss: 0.0112 - acc: 0.9910 - val_loss: 0.0141 - val_acc: 0.9856\n",
      "Epoch 597/600\n",
      " - 0s - loss: 0.0112 - acc: 0.9906 - val_loss: 0.0115 - val_acc: 0.9893\n",
      "Epoch 598/600\n",
      " - 0s - loss: 0.0111 - acc: 0.9910 - val_loss: 0.0220 - val_acc: 0.9698\n",
      "Epoch 599/600\n",
      " - 0s - loss: 0.0129 - acc: 0.9879 - val_loss: 0.0153 - val_acc: 0.9843\n",
      "Epoch 600/600\n",
      " - 0s - loss: 0.0114 - acc: 0.9904 - val_loss: 0.0217 - val_acc: 0.9694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20cca7b2a90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=600, batch_size=512,  verbose=2 ,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
